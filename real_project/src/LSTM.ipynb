{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f0d7f9",
   "metadata": {},
   "source": [
    "Combine data into one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78c457f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def merge_csv_files(folder_path, output_file=\"merged.csv\"):\n",
    "    csv_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df.columns = [col.strip() for col in df.columns]\n",
    "        dfs.append(df)\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Use correct relative path for CICIDS2017 folder\n",
    "merge_csv_files(\"../../CICIDS2017\", \"merged.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4100c63",
   "metadata": {},
   "source": [
    "Create two datasets, one is raw, the other is processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9089ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (2406132, 79)\n",
      "Number of features: 78\n",
      "First few feature names: ['Destination Port', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std']\n",
      "Label distribution:\n",
      " Label\n",
      "0    1931847\n",
      "1     474285\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==== SETTINGS ====\n",
    "file_path = \"merged.csv\"\n",
    "fraction = 0.45  # % of data\n",
    "\n",
    "# ==== 1. Load in chunks to avoid memory blowups ====\n",
    "chunks = []\n",
    "chunk_size = 10_000\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "    # Strip whitespace from column names\n",
    "    chunk.columns = chunk.columns.str.strip()\n",
    "    \n",
    "    # 2. Downcast numerics\n",
    "    for col in chunk.select_dtypes(include=['int', 'float']).columns:\n",
    "        if pd.api.types.is_integer_dtype(chunk[col]):\n",
    "            chunk[col] = pd.to_numeric(chunk[col], downcast='integer')\n",
    "        else:\n",
    "            chunk[col] = pd.to_numeric(chunk[col], downcast='float')\n",
    "    \n",
    "    # 3. Replace NaN/Inf inside chunk\n",
    "    chunk = chunk.replace([np.inf, -np.inf], np.nan)  # unify to NaN first\n",
    "    chunk = chunk.fillna(0)                           # replace NaN with 0\n",
    "    \n",
    "    chunks.append(chunk)\n",
    "\n",
    "data = pd.concat(chunks, ignore_index=True)\n",
    "del chunks  # free memory\n",
    "\n",
    "# ==== 4. Homogeneous sampling ====\n",
    "data = data.sample(frac=fraction, random_state=42)\n",
    "\n",
    "# ==== 5. Cap extreme values (optional: prevent exploding features) ====\n",
    "# Choose a reasonable cap per feature (e.g., 99.9th percentile)\n",
    "for col in data.select_dtypes(include=[np.number]).columns:\n",
    "    cap_value = data[col].quantile(0.999)  # 99.9% cap\n",
    "    data[col] = np.clip(data[col], a_min=None, a_max=cap_value)\n",
    "\n",
    "# ==== 6. Convert all numeric to float32 for PyTorch ====\n",
    "for col in data.columns:\n",
    "    if pd.api.types.is_numeric_dtype(data[col]):\n",
    "        data[col] = data[col].astype(np.float32)\n",
    "\n",
    "# ==== 7. Convert Label column to binary ====\n",
    "if \"Label\" in data.columns:\n",
    "    data[\"Label\"] = data[\"Label\"].apply(lambda x: 0 if str(x).strip().upper() == \"BENIGN\" else 1).astype(np.int32)\n",
    "\n",
    "# ==== Final assignment ====\n",
    "datadf = data.copy()\n",
    "ftnames = [c.strip() for c in datadf.columns if c.strip() != \"Label\"]\n",
    "\n",
    "# ==== Quick sanity check ====\n",
    "print(f\"Final shape: {datadf.shape}\")\n",
    "print(f\"Number of features: {len(ftnames)}\")\n",
    "print(\"First few feature names:\", ftnames[:10])\n",
    "print(\"Label distribution:\\n\", datadf['Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93d539",
   "metadata": {},
   "source": [
    "LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b25857e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Label'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 1. Prepare data\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[32m     16\u001b[39m data_numeric = data.select_dtypes(include=[np.number]).copy()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m X = \u001b[43mdata_numeric\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLabel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.values\n\u001b[32m     19\u001b[39m y = data_numeric[\u001b[33m\"\u001b[39m\u001b[33mLabel\u001b[39m\u001b[33m\"\u001b[39m].values.astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     21\u001b[39m scaler = MinMaxScaler()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\pandas\\core\\frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\pandas\\core\\generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\pandas\\core\\generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['Label'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# ==============================\n",
    "# 1. Prepare data\n",
    "# ==============================\n",
    "data_numeric = data.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "X = data_numeric.drop(columns=[\"Label\"]).values\n",
    "y = data_numeric[\"Label\"].values.astype(int)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape for LSTM: (samples, timesteps, features)\n",
    "# Here we treat each row as one timestep sequence of length 1\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==============================\n",
    "# 2. Define LSTM Model\n",
    "# ==============================\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        out = hn[-1]\n",
    "        out = self.fc(out)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "# ==============================\n",
    "# 3. Optuna Objective\n",
    "# ==============================\n",
    "def objective(trial):\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 16, 128)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "\n",
    "    model = LSTMModel(X.shape[2], hidden_dim, num_layers, dropout).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                            torch.tensor(y_train, dtype=torch.float32)),\n",
    "                              batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                                          torch.tensor(y_val, dtype=torch.float32)),\n",
    "                            batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for epoch in range(5):  # keep short for tuning\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device).unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    y_probs = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = model(xb).cpu().numpy()\n",
    "            y_probs.extend(preds.flatten())\n",
    "\n",
    "    y_val_pred = np.array(y_probs)\n",
    "    pr_auc = average_precision_score(y_val, y_val_pred)\n",
    "\n",
    "    return pr_auc\n",
    "\n",
    "# ==============================\n",
    "# 4. Run Optuna Study\n",
    "# ==============================\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best trial:\", study.best_trial.params)\n",
    "\n",
    "# ==============================\n",
    "# 5. Retrain best model on train+val\n",
    "# ==============================\n",
    "best_params = study.best_trial.params\n",
    "best_model = LSTMModel(X.shape[2], best_params[\"hidden_dim\"],\n",
    "                       best_params[\"num_layers\"], best_params[\"dropout\"]).to(device)\n",
    "optimizer = torch.optim.Adam(best_model.parameters(), lr=best_params[\"lr\"])\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "trainval_loader = DataLoader(TensorDataset(torch.tensor(np.concatenate([X_train, X_val]), dtype=torch.float32),\n",
    "                                           torch.tensor(np.concatenate([y_train, y_val]), dtype=torch.float32)),\n",
    "                             batch_size=best_params[\"batch_size\"], shuffle=True)\n",
    "\n",
    "for epoch in range(15):  # longer training\n",
    "    best_model.train()\n",
    "    for xb, yb in trainval_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        preds = best_model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# ==============================\n",
    "# 6. Test Evaluation with threshold selection\n",
    "# ==============================\n",
    "test_loader = DataLoader(TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                                       torch.tensor(y_test, dtype=torch.float32)),\n",
    "                         batch_size=128, shuffle=False)\n",
    "\n",
    "best_model.eval()\n",
    "y_probs = []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        preds = best_model(xb).cpu().numpy()\n",
    "        y_probs.extend(preds.flatten())\n",
    "y_probs = np.array(y_probs)\n",
    "\n",
    "# Pick best threshold by F1\n",
    "thresholds = np.linspace(0.1, 0.9, 50)\n",
    "f1_scores = [f1_score(y_test, (y_probs >= t).astype(int)) for t in thresholds]\n",
    "best_thresh = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "y_pred = (y_probs >= best_thresh).astype(int)\n",
    "\n",
    "print(\"Test AUROC:\", roc_auc_score(y_test, y_probs))\n",
    "print(\"Test PR AUC:\", average_precision_score(y_test, y_probs))\n",
    "print(\"Best Threshold:\", best_thresh)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "246a0dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\python.exe\n",
      "Torch location: c:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\__init__.py\n",
      "Torch version: 2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Torch location:\", torch.__file__)\n",
    "print(\"Torch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a3f278",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12d6f2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     66\u001b[39m device = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# 5. Loss + optimizer\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[32m     73\u001b[39m num_positives = np.sum(y_seq)            \u001b[38;5;66;03m# count anomalies\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1337\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1338\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1340\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    899\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m900\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    903\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    904\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    905\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    910\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    911\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:283\u001b[39m, in \u001b[36mRNNBase._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, recurse=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    282\u001b[39m     \u001b[38;5;28mself\u001b[39m._flat_weight_refs = []\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     ret = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     \u001b[38;5;66;03m# Resets _flat_weights\u001b[39;00m\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Note: be v. careful before removing this, as 3rd party device types\u001b[39;00m\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# likely rely on this behavior to properly .to() modules like LSTM.\u001b[39;00m\n\u001b[32m    288\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_flat_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    923\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    924\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    925\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    928\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    930\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1320\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1321\u001b[39m             device,\n\u001b[32m   1322\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m             non_blocking,\n\u001b[32m   1324\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1325\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# ==============================\n",
    "# 1. Prepare data\n",
    "# ==============================\n",
    "# Assume 'data' is your sampled DataFrame\n",
    "data_numeric = data.select_dtypes(include=[np.number]).astype(np.float32)\n",
    "data_numeric = data_numeric.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "data_numeric = data_numeric.clip(-1e6, 1e6)\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data_numeric)\n",
    "\n",
    "# Suppose you have a 'Label' column in original data\n",
    "labels = np.where(data['Label'] == 'BENIGN', 0, 1).astype(np.float32)\n",
    "\n",
    "# ==============================\n",
    "# 2. Create sequences\n",
    "# ==============================\n",
    "def create_seq(data, labels, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(labels[i+seq_length])  # predict next timestep\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)\n",
    "\n",
    "seq_length = 20\n",
    "X_seq, y_seq = create_seq(data_scaled, labels, seq_length)\n",
    "\n",
    "# ==============================\n",
    "# 3. DataLoader\n",
    "# ==============================\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(torch.tensor(X_seq), torch.tensor(y_seq))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ==============================\n",
    "# 4. LSTM Model\n",
    "# ==============================\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)  # single output for binary\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        batch_size = x.size(0)\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.zeros(self.layer_dim, batch_size, self.hidden_dim).to(x.device)\n",
    "            c0 = torch.zeros(self.layer_dim, batch_size, self.hidden_dim).to(x.device)\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out, hn\n",
    "\n",
    "input_dim = X_seq.shape[2]\n",
    "hidden_dim = 128\n",
    "layer_dim = 1\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "# ==============================\n",
    "# 5. Loss + optimizer\n",
    "# ==============================\n",
    "num_positives = np.sum(y_seq)            # count anomalies\n",
    "num_negatives = len(y_seq) - num_positives\n",
    "pos_weight = torch.tensor(num_negatives / num_positives, dtype=torch.float32)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ==============================\n",
    "# 6. Training loop\n",
    "# ==============================\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_X, batch_Y in train_loader:\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(batch_X)\n",
    "        loss = criterion(logits, batch_Y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch_X.size(0)\n",
    "        \n",
    "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "        correct += (preds == batch_Y).sum().item()\n",
    "        total += batch_X.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.6f}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "# ==============================\n",
    "# 7. Evaluation\n",
    "# ==============================\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_seq).to(device)\n",
    "    logits, hidden = model(X_tensor)\n",
    "    probs = torch.sigmoid(logits).cpu().numpy()\n",
    "    predictions = (probs > 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "cm = confusion_matrix(y_seq, predictions)\n",
    "precision = precision_score(y_seq, predictions, zero_division=0)\n",
    "recall = recall_score(y_seq, predictions, zero_division=0)\n",
    "f1 = f1_score(y_seq, predictions, zero_division=0)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "# Optional: use last hidden state as suspicion score\n",
    "suspicion_scores = np.linalg.norm(hidden[-1].cpu().numpy(), axis=1)\n",
    "print(\"Suspicion scores (first 10):\", suspicion_scores[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2ab42",
   "metadata": {},
   "source": [
    "# CELLS AFTER THIS ARE TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8cabcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of anomalies detected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred.sum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(y_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m     56\u001b[39m results = evaluate_anomalies(\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     pred=\u001b[43mpred\u001b[49m.numpy(),\n\u001b[32m     58\u001b[39m     y_true_seq=y_seq,\n\u001b[32m     59\u001b[39m     original_df=data,\n\u001b[32m     60\u001b[39m     label_col=\u001b[33m\"\u001b[39m\u001b[33mLabel\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     61\u001b[39m     top_pct=\u001b[32m5\u001b[39m\n\u001b[32m     62\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_anomalies(pred, y_true_seq, original_df, label_col=\"Label\", top_pct=5):\n",
    "    \"\"\"\n",
    "    Evaluate LSTM predictions against CICIDS2017 labels.\n",
    "\n",
    "    Parameters:\n",
    "        pred: np.ndarray, predicted next-step values [num_samples, num_features]\n",
    "        y_true_seq: np.ndarray, true next-step values [num_samples, num_features]\n",
    "        original_df: pd.DataFrame, original DataFrame including 'Label'\n",
    "        label_col: str, name of column with BENIGN/anomaly labels\n",
    "        top_pct: float, percentile of suspicion scores to label anomalies\n",
    "\n",
    "    Returns:\n",
    "        dict with MSE, confusion matrix, precision, recall, F1, anomalies detected\n",
    "    \"\"\"\n",
    "    # 1. Compute suspicion scores (L2 norm per sample)\n",
    "    suspicion_scores = np.linalg.norm(pred - y_true_seq, axis=1)\n",
    "\n",
    "    # 2. Determine threshold\n",
    "    threshold = np.percentile(suspicion_scores, 100 - top_pct)\n",
    "\n",
    "    # 3. Predicted anomaly labels (1 = anomaly, 0 = benign)\n",
    "    y_pred = (suspicion_scores > threshold).astype(int)\n",
    "\n",
    "    # 4. Ground truth anomaly labels (1 = anomaly, 0 = BENIGN)\n",
    "    # Align y_true_seq with original_df\n",
    "    start_idx = original_df.shape[0] - y_true_seq.shape[0]  # account for sequence offset\n",
    "    y_true_labels = original_df[label_col].iloc[start_idx:].apply(lambda x: 0 if x == \"BENIGN\" else 1).to_numpy()\n",
    "\n",
    "    # 5. Compute metrics\n",
    "    mse = ((pred - y_true_seq) ** 2).mean()\n",
    "    cm = confusion_matrix(y_true_labels, y_pred)\n",
    "    precision = precision_score(y_true_labels, y_pred)\n",
    "    recall = recall_score(y_true_labels, y_pred)\n",
    "    f1 = f1_score(y_true_labels, y_pred)\n",
    "\n",
    "    results = {\n",
    "        \"MSE\": mse,\n",
    "        \"ConfusionMatrix\": cm,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1,\n",
    "        \"SuspicionScores\": suspicion_scores,\n",
    "        \"PredictedAnomalies\": y_pred\n",
    "    }\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse:.6f}\")\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "    print(f\"Number of anomalies detected: {y_pred.sum()} / {len(y_pred)}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results = evaluate_anomalies(\n",
    "    pred=pred.numpy(),\n",
    "    y_true_seq=y_seq,\n",
    "    original_df=data,\n",
    "    label_col=\"Label\",\n",
    "    top_pct=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4c0776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def evaluate_model(model, X, y_true, threshold=0.5, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluate a trained LSTM model on sequences.\n",
    "    \n",
    "    Args:\n",
    "        model      : trained LSTM model\n",
    "        X          : input tensor, shape [num_samples, seq_length, num_features]\n",
    "        y_true     : true labels tensor, shape [num_samples, 1]\n",
    "        threshold  : threshold to consider anomaly (for binary classification)\n",
    "        device     : 'cpu' or 'cuda'\n",
    "    \n",
    "    Returns:\n",
    "        metrics dict: contains loss, accuracy, predictions, suspicion scores\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    X, y_true = X.to(device), y_true.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred, _, _ = model(X)  # output shape: [num_samples, 1]\n",
    "        \n",
    "        # Loss\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        loss = loss_fn(y_pred, y_true).item()\n",
    "        \n",
    "        # Convert predictions to binary labels\n",
    "        y_pred_labels = (y_pred >= threshold).float()\n",
    "        \n",
    "        # Accuracy\n",
    "        correct = (y_pred_labels == y_true).sum().item()\n",
    "        total = y_true.size(0)\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        # Suspicion score: predicted probability of anomaly\n",
    "        suspicion_scores = y_pred.squeeze().cpu().numpy()\n",
    "        \n",
    "    return {\n",
    "        \"loss\": loss,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"y_pred_labels\": y_pred_labels.cpu().numpy(),\n",
    "        \"suspicion_scores\": suspicion_scores\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "metrics = evaluate_model(model, trainX, trainY)\n",
    "print(\"Loss:\", metrics[\"loss\"])\n",
    "print(\"Accuracy:\", metrics[\"accuracy\"])\n",
    "print(\"Suspicion scores (first 10):\", metrics[\"suspicion_scores\"][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486cb5f7",
   "metadata": {},
   "source": [
    "#CELLS AFTER THIS ARE PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7796be70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: {np.int64(0): np.int64(340905), np.int64(1): np.int64(83706)}\n",
      "X_seq shape: (424561, 50, 78) y_seq shape: (424561,)\n",
      "Using device: cuda\n",
      "\n",
      "--- Baseline: Majority class ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-18 00:33:23,376] A new study created in memory with name: no-name-0dc5f4c2-2bad-4068-9c0e-5388ae857d24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.802751051075807 F1: 0.0\n",
      "\n",
      "--- Baseline: Random guessing ---\n",
      "Acc: 0.5000294418993558 F1: 0.28207122805830825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gokde\\AppData\\Local\\Temp\\ipykernel_13664\\484083997.py:151: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
      "[W 2025-08-18 00:33:28,730] Trial 0 failed with parameters: {'hidden_dim': 64, 'layer_dim': 2, 'lr': 0.00013007416807320993, 'batch_size': 64} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gokde\\AppData\\Local\\Temp\\ipykernel_13664\\484083997.py\", line 153, in objective\n",
      "    return train_and_eval(hidden_dim=hidden_dim, layer_dim=layer_dim, lr=lr,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gokde\\AppData\\Local\\Temp\\ipykernel_13664\\484083997.py\", line 73, in train_and_eval\n",
      "    val_loader = make_loader(X_val, y_val, batch_size=batch_size, shuffle=False)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gokde\\AppData\\Local\\Temp\\ipykernel_13664\\484083997.py\", line 47, in make_loader\n",
      "    dataset = TensorDataset(torch.tensor(X), torch.tensor(y))\n",
      "                            ^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-18 00:33:28,749] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 157\u001b[39m\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_and_eval(hidden_dim=hidden_dim, layer_dim=layer_dim, lr=lr,\n\u001b[32m    154\u001b[39m                           batch_size=batch_size, epochs=\u001b[32m5\u001b[39m)  \u001b[38;5;66;03m# fewer epochs for tuning\u001b[39;00m\n\u001b[32m    156\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# try 10 configs\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest hyperparameters:\u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\optuna\\study\\study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 153\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    151\u001b[39m lr = trial.suggest_loguniform(\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1e-4\u001b[39m, \u001b[32m1e-2\u001b[39m)\n\u001b[32m    152\u001b[39m batch_size = trial.suggest_categorical(\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m, [\u001b[32m32\u001b[39m, \u001b[32m64\u001b[39m, \u001b[32m128\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_and_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mtrain_and_eval\u001b[39m\u001b[34m(hidden_dim, layer_dim, lr, batch_size, epochs)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_and_eval\u001b[39m(hidden_dim=\u001b[32m32\u001b[39m, layer_dim=\u001b[32m1\u001b[39m, lr=\u001b[32m1e-3\u001b[39m, batch_size=\u001b[32m64\u001b[39m, epochs=\u001b[32m10\u001b[39m):\n\u001b[32m     72\u001b[39m     train_loader = make_loader(X_train, y_train, batch_size=batch_size, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     val_loader = \u001b[43mmake_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     model = LSTMModel(input_dim=X_seq.shape[\u001b[32m2\u001b[39m], hidden_dim=hidden_dim, layer_dim=layer_dim).to(device)\n\u001b[32m     76\u001b[39m     num_neg, num_pos = np.sum(y_train == \u001b[32m0\u001b[39m), np.sum(y_train == \u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mmake_loader\u001b[39m\u001b[34m(X, y, batch_size, shuffle)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_loader\u001b[39m(X, y, batch_size=\u001b[32m64\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     dataset = TensorDataset(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, torch.tensor(y))\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# ==============================\n",
    "# 1. Prepare data\n",
    "# ==============================\n",
    "# Assuming 'data' is already the 5% sampled DataFrame from merged.csv\n",
    "data_numeric = data.select_dtypes(include=[np.number]).copy()\n",
    "data_numeric = data_numeric.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(data_numeric)\n",
    "\n",
    "labels = data['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1).to_numpy()\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(\"Class distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "def create_seq(X, y, seq_length=50):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq, dtype=np.float32), np.array(y_seq, dtype=np.float32)\n",
    "\n",
    "seq_length = 50\n",
    "X_seq, y_seq = create_seq(X_scaled, labels, seq_length)\n",
    "print(\"X_seq shape:\", X_seq.shape, \"y_seq shape:\", y_seq.shape)\n",
    "\n",
    "# Train/validation split\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_val = X_seq[:split], X_seq[split:]\n",
    "y_train, y_val = y_seq[:split], y_seq[split:]\n",
    "\n",
    "# ==============================\n",
    "# 2. Dataset + DataLoader\n",
    "# ==============================\n",
    "def make_loader(X, y, batch_size=64, shuffle=True):\n",
    "    dataset = TensorDataset(torch.tensor(X), torch.tensor(y))\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# ==============================\n",
    "# 3. Define LSTM\n",
    "# ==============================\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32, layer_dim=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        last_hidden = out[:, -1, :]\n",
    "        logit = self.fc(last_hidden)\n",
    "        return logit, last_hidden\n",
    "\n",
    "# ==============================\n",
    "# 4. Training & Evaluation\n",
    "# ==============================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def train_and_eval(hidden_dim=32, layer_dim=1, lr=1e-3, batch_size=64, epochs=10):\n",
    "    train_loader = make_loader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = make_loader(X_val, y_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = LSTMModel(input_dim=X_seq.shape[2], hidden_dim=hidden_dim, layer_dim=layer_dim).to(device)\n",
    "    num_neg, num_pos = np.sum(y_train == 0), np.sum(y_train == 1)\n",
    "    pos_weight = torch.tensor([num_neg / num_pos], dtype=torch.float32).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # --- Training loop ---\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, total_correct = 0, 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device, dtype=torch.float32).unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(batch_X)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            probs = torch.sigmoid(logits)\n",
    "            total_loss += loss.item() * batch_X.size(0)\n",
    "            total_correct += ((probs > 0.5) == batch_y).sum().item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader.dataset):.6f}, \"\n",
    "              f\"Accuracy: {total_correct/len(train_loader.dataset):.4f}\")\n",
    "\n",
    "    # --- Validation evaluation ---\n",
    "    model.eval()\n",
    "    all_probs, all_preds, all_hidden = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            logits, last_hidden = model(batch_X)\n",
    "            probs = torch.sigmoid(logits).cpu()\n",
    "            preds = (probs > 0.5).int()\n",
    "            all_probs.append(probs)\n",
    "            all_preds.append(preds)\n",
    "            all_hidden.append(last_hidden.cpu())\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy().flatten()\n",
    "    all_preds = torch.cat(all_preds).numpy().flatten()\n",
    "    all_hidden = torch.cat(all_hidden).numpy()\n",
    "    suspicion_scores = np.linalg.norm(all_hidden, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(y_val, all_preds)\n",
    "    prec = precision_score(y_val, all_preds, zero_division=0)\n",
    "    rec = recall_score(y_val, all_preds, zero_division=0)\n",
    "    f1 = f1_score(y_val, all_preds, zero_division=0)\n",
    "    auroc = roc_auc_score(y_val, all_probs)\n",
    "    pr_auc = average_precision_score(y_val, all_probs)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n",
    "    print(f\"AUROC: {auroc:.4f}, PR-AUC: {pr_auc:.4f}\")\n",
    "    print(\"Suspicion scores (first 10):\", suspicion_scores[:10])\n",
    "\n",
    "    return pr_auc  # use PR-AUC for hyperparameter optimization\n",
    "\n",
    "# ==============================\n",
    "# 5. Baseline sanity checks\n",
    "# ==============================\n",
    "y_majority = np.zeros_like(y_val)\n",
    "y_random = np.random.randint(0, 2, size=len(y_val))\n",
    "\n",
    "print(\"\\n--- Baseline: Majority class ---\")\n",
    "print(\"Acc:\", (y_majority == y_val).mean(), \"F1:\", f1_score(y_val, y_majority, zero_division=0))\n",
    "\n",
    "print(\"\\n--- Baseline: Random guessing ---\")\n",
    "print(\"Acc:\", (y_random == y_val).mean(), \"F1:\", f1_score(y_val, y_random, zero_division=0))\n",
    "\n",
    "# ==============================\n",
    "# 6. Bayesian optimization with Optuna\n",
    "# ==============================\n",
    "def objective(trial):\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [32, 64, 128])\n",
    "    layer_dim = trial.suggest_int(\"layer_dim\", 1, 3)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    return train_and_eval(hidden_dim=hidden_dim, layer_dim=layer_dim, lr=lr,\n",
    "                          batch_size=batch_size, epochs=5)  # fewer epochs for tuning\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)  # try 10 configs\n",
    "\n",
    "print(\"\\nBest hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c21605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: {np.int64(0): np.int64(340905), np.int64(1): np.int64(83706)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-18 14:17:41,013] A new study created in memory with name: no-name-3597c1c1-3405-4a2a-9c30-49e59a5054bb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seq shape: (424561, 50, 78) y_seq shape: (424561,)\n",
      "Using device: cuda\n",
      "\n",
      "--- Baseline: Majority class ---\n",
      "Acc: 0.802751051075807 F1: 0.0\n",
      "\n",
      "--- Baseline: Random guessing ---\n",
      "Acc: 0.5008655918410608 F1: 0.2837926897274279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-08-18 14:18:12,859] Trial 0 failed with parameters: {'hidden_dim': 32, 'layer_dim': 2, 'lr': 0.005404325181626058, 'batch_size': 128, 'dropout': 0.019813085892406768} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gokde\\AppData\\Local\\Temp\\ipykernel_20960\\3520822581.py\", line 136, in objective\n",
      "    pr_auc, _, _ = train_and_eval(hidden_dim, layer_dim, lr, batch_size, epochs=5, dropout=dropout)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gokde\\AppData\\Local\\Temp\\ipykernel_20960\\3520822581.py\", line 89, in train_and_eval\n",
      "    logits, _ = model(batch_X)\n",
      "                ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gokde\\AppData\\Local\\Temp\\ipykernel_20960\\3520822581.py\", line 62, in forward\n",
      "    logit = self.fc(last_hidden)\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-18 14:18:12,914] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 140\u001b[39m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pr_auc\n\u001b[32m    139\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest hyperparameters:\u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;66;03m# 7. Retrain best model on train+val\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\optuna\\study\\study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 136\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    134\u001b[39m batch_size = trial.suggest_categorical(\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m, [\u001b[32m32\u001b[39m, \u001b[32m64\u001b[39m, \u001b[32m128\u001b[39m])\n\u001b[32m    135\u001b[39m dropout = trial.suggest_float(\u001b[33m\"\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.0\u001b[39m, \u001b[32m0.5\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m pr_auc, _, _ = \u001b[43mtrain_and_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pr_auc\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 89\u001b[39m, in \u001b[36mtrain_and_eval\u001b[39m\u001b[34m(hidden_dim, layer_dim, lr, batch_size, epochs, dropout)\u001b[39m\n\u001b[32m     87\u001b[39m batch_X, batch_y = batch_X.to(device), batch_y.to(device, dtype=torch.float32).unsqueeze(\u001b[32m1\u001b[39m)\n\u001b[32m     88\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m logits, _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m loss = criterion(logits, batch_y)\n\u001b[32m     91\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mLSTMModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     60\u001b[39m out, (hn, cn) = \u001b[38;5;28mself\u001b[39m.lstm(x)\n\u001b[32m     61\u001b[39m last_hidden = out[:, -\u001b[32m1\u001b[39m, :]\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m logit = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m logit, last_hidden\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gokde\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# ==============================\n",
    "# 1. Prepare data\n",
    "# ==============================\n",
    "data_numeric = data.select_dtypes(include=[np.number]).copy()\n",
    "data_numeric = data_numeric.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(data_numeric)\n",
    "\n",
    "labels = data['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1).to_numpy()\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(\"Class distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "def create_seq(X, y, seq_length=50):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i+seq_length])\n",
    "        y_seq.append(y[i+seq_length])\n",
    "    return np.array(X_seq, dtype=np.float32), np.array(y_seq, dtype=np.float32)\n",
    "\n",
    "seq_length = 50\n",
    "X_seq, y_seq = create_seq(X_scaled, labels, seq_length)\n",
    "print(\"X_seq shape:\", X_seq.shape, \"y_seq shape:\", y_seq.shape)\n",
    "\n",
    "# Train/validation split\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_val = X_seq[:split], X_seq[split:]\n",
    "y_train, y_val = y_seq[:split], y_seq[split:]\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 2. Dataset + DataLoader\n",
    "# ==============================\n",
    "def make_loader(X, y, batch_size=64, shuffle=True):\n",
    "    dataset = TensorDataset(torch.tensor(X), torch.tensor(y))\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# ==============================\n",
    "# 3. Define LSTM\n",
    "# ==============================\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32, layer_dim=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        last_hidden = out[:, -1, :]\n",
    "        logit = self.fc(last_hidden)\n",
    "        return logit, last_hidden\n",
    "\n",
    "# ==============================\n",
    "# 4. Training function (used in Optuna)\n",
    "# ==============================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def train_and_eval(hidden_dim=32, layer_dim=1, lr=1e-3, batch_size=64, epochs=10, dropout=0.0):\n",
    "    train_loader = make_loader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = make_loader(X_val, y_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = LSTMModel(input_dim=X_seq.shape[2], hidden_dim=hidden_dim, layer_dim=layer_dim, dropout=dropout).to(device)\n",
    "    num_neg, num_pos = np.sum(y_train == 0), np.sum(y_train == 1)\n",
    "    pos_weight = torch.tensor([num_neg / num_pos], dtype=torch.float32).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # --- Training loop ---\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, total_correct = 0, 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device, dtype=torch.float32).unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(batch_X)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            probs = torch.sigmoid(logits)\n",
    "            total_loss += loss.item() * batch_X.size(0)\n",
    "            total_correct += ((probs > 0.5) == batch_y).sum().item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader.dataset):.6f}, \"\n",
    "              f\"Accuracy: {total_correct/len(train_loader.dataset):.4f}\")\n",
    "\n",
    "    # --- Validation evaluation ---\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            logits, _ = model(batch_X)\n",
    "            probs = torch.sigmoid(logits).cpu()\n",
    "            all_probs.append(probs)\n",
    "    all_probs = torch.cat(all_probs).numpy().flatten()\n",
    "\n",
    "    pr_auc = average_precision_score(y_val, all_probs)\n",
    "    return pr_auc, model, all_probs  # return probs for threshold tuning\n",
    "\n",
    "# ==============================\n",
    "# 5. Baseline sanity checks\n",
    "# ==============================\n",
    "y_majority = np.zeros_like(y_val)\n",
    "y_random = np.random.randint(0, 2, size=len(y_val))\n",
    "\n",
    "print(\"\\n--- Baseline: Majority class ---\")\n",
    "print(\"Acc:\", (y_majority == y_val).mean(), \"F1:\", f1_score(y_val, y_majority, zero_division=0))\n",
    "\n",
    "print(\"\\n--- Baseline: Random guessing ---\")\n",
    "print(\"Acc:\", (y_random == y_val).mean(), \"F1:\", f1_score(y_val, y_random, zero_division=0))\n",
    "\n",
    "# ==============================\n",
    "# 6. Optuna optimization\n",
    "# ==============================\n",
    "def objective(trial):\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [32, 64, 128])\n",
    "    layer_dim = trial.suggest_int(\"layer_dim\", 1, 3)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    pr_auc, _, _ = train_and_eval(hidden_dim, layer_dim, lr, batch_size, epochs=5, dropout=dropout)\n",
    "    return pr_auc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(\"\\nBest hyperparameters:\", study.best_params)\n",
    "\n",
    "# ==============================\n",
    "# 7. Retrain best model on train+val\n",
    "# ==============================\n",
    "best_params = study.best_params\n",
    "X_trainval = np.concatenate([X_train, X_val])\n",
    "y_trainval = np.concatenate([y_train, y_val])\n",
    "\n",
    "trainval_loader = make_loader(X_trainval, y_trainval, batch_size=best_params[\"batch_size\"], shuffle=True)\n",
    "\n",
    "best_model = LSTMModel(input_dim=X_seq.shape[2],\n",
    "                       hidden_dim=best_params[\"hidden_dim\"],\n",
    "                       layer_dim=best_params[\"layer_dim\"],\n",
    "                       dropout=best_params[\"dropout\"]).to(device)\n",
    "optimizer = torch.optim.Adam(best_model.parameters(), lr=best_params[\"lr\"])\n",
    "num_neg, num_pos = np.sum(y_trainval == 0), np.sum(y_trainval == 1)\n",
    "pos_weight = torch.tensor([num_neg / num_pos], dtype=torch.float32).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "for epoch in range(15):\n",
    "    best_model.train()\n",
    "    for batch_X, batch_y in trainval_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device, dtype=torch.float32).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = best_model(batch_X)\n",
    "        loss = criterion(logits, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# ==============================\n",
    "# 8. Test evaluation + threshold tuning\n",
    "# ==============================\n",
    "test_loader = make_loader(X_val, y_val, batch_size=128, shuffle=False)  # replace with real test if available\n",
    "best_model.eval()\n",
    "all_probs = []\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        logits, _ = best_model(batch_X)\n",
    "        probs = torch.sigmoid(logits).cpu()\n",
    "        all_probs.append(probs)\n",
    "all_probs = torch.cat(all_probs).numpy().flatten()\n",
    "\n",
    "# Tune threshold based on F1\n",
    "thresholds = np.linspace(0.1, 0.9, 50)\n",
    "f1_scores = [f1_score(y_val, (all_probs >= t).astype(int)) for t in thresholds]\n",
    "best_thresh = thresholds[np.argmax(f1_scores)]\n",
    "y_pred = (all_probs >= best_thresh).astype(int)\n",
    "\n",
    "print(\"Best threshold:\", best_thresh)\n",
    "print(\"Precision:\", precision_score(y_val, y_pred))\n",
    "print(\"Recall:\", recall_score(y_val, y_pred))\n",
    "print(\"F1:\", f1_score(y_val, y_pred))\n",
    "print(\"AUROC:\", roc_auc_score(y_val, all_probs))\n",
    "print(\"PR-AUC:\", average_precision_score(y_val, all_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40da2c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Analysis ===\n",
      "Dataset shape: (424611, 79)\n",
      "\n",
      "Label distribution:\n",
      "Label\n",
      "BENIGN                        340905\n",
      "DoS Hulk                       34754\n",
      "PortScan                       23826\n",
      "DDoS                           19194\n",
      "DoS GoldenEye                   1528\n",
      "FTP-Patator                     1232\n",
      "SSH-Patator                      878\n",
      "DoS slowloris                    874\n",
      "DoS Slowhttptest                 804\n",
      "Bot                              291\n",
      "Web Attack  Brute Force         226\n",
      "Web Attack  XSS                  86\n",
      "Web Attack  Sql Injection         7\n",
      "Infiltration                       4\n",
      "Heartbleed                         2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique labels: ['BENIGN' 'DoS Hulk' 'DDoS' 'PortScan' 'DoS slowloris' 'DoS GoldenEye'\n",
      " 'FTP-Patator' 'DoS Slowhttptest' 'Bot' 'SSH-Patator'\n",
      " 'Web Attack  Brute Force' 'Web Attack  XSS' 'Heartbleed'\n",
      " 'Web Attack  Sql Injection' 'Infiltration']\n",
      "\n",
      "Binary label distribution: {np.int64(0): np.int64(340905), np.int64(1): np.int64(83706)}\n",
      "Attack ratio: 0.1971\n",
      "\n",
      "=== Feature Engineering ===\n",
      "Number of numeric features: 78\n",
      "\n",
      "Checking data quality...\n",
      "Columns with infinite values: 2\n",
      "Columns with NaN values: 1\n",
      "Zero variance columns: 8\n",
      "Removing zero variance columns: ['Bwd PSH Flags', 'Bwd URG Flags', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
      "Removing 24 highly correlated features\n",
      "Final feature count: 46\n",
      "\n",
      "=== Scaling and Splitting ===\n",
      "Scaled data range: [-6990444.500, 106000000.000]\n",
      "Scaled data mean: 19160.223, std: 711925.750\n",
      "Train samples: 254766 (attack rate: 0.1971)\n",
      "Val samples: 84922 (attack rate: 0.1971)\n",
      "Test samples: 84923 (attack rate: 0.1971)\n",
      "\n",
      "=== Baseline Model Check ===\n",
      "Random Forest - AUC: 0.9997\n",
      "Random Forest - F1: 0.9954\n",
      "\n",
      "Creating sequences with window size: 5\n",
      "Train sequences: (254762, 5, 46)\n",
      "Val sequences: (84918, 5, 46)\n",
      "Test sequences: (84919, 5, 46)\n",
      "\n",
      "Using device: cuda\n",
      "\n",
      "=== Training LSTM Model ===\n",
      "Epoch  1/25: Loss=0.3113, Val AUC=0.9869\n",
      "Epoch  6/25: Loss=0.2369, Val AUC=0.9872\n",
      "Epoch 11/25: Loss=0.2408, Val AUC=0.9876\n",
      "Epoch 16/25: Loss=0.2423, Val AUC=0.9929\n",
      "Epoch 21/25: Loss=0.2355, Val AUC=0.9894\n",
      "Epoch 25/25: Loss=0.2410, Val AUC=0.9909\n",
      "\n",
      "=== Final Evaluation ===\n",
      "Best threshold: 0.852\n",
      "Test AUC: 0.9915\n",
      "Test PR-AUC: 0.9699\n",
      "Test F1: 0.8939\n",
      "Test Precision: 0.9266\n",
      "Test Recall: 0.8634\n",
      "\n",
      "Confusion Matrix:\n",
      "[[67035  1145]\n",
      " [ 2286 14453]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analysis Complete ===\n",
      "If AUC is still low (<0.7), consider:\n",
      "1. Check if your labels are correct\n",
      "2. Try different feature engineering\n",
      "3. Use a different model architecture\n",
      "4. Ensure your data has temporal structure suitable for LSTM\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==============================\n",
    "# 1. Data Analysis and Preprocessing\n",
    "# ==============================\n",
    "print(\"=== Data Analysis ===\")\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"\\nLabel distribution:\")\n",
    "label_counts = data['Label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# Check label types\n",
    "unique_labels = data['Label'].unique()\n",
    "print(f\"\\nUnique labels: {unique_labels}\")\n",
    "\n",
    "# Create binary labels - be more explicit about mapping\n",
    "def create_binary_labels(labels):\n",
    "    \"\"\"Convert labels to binary (0=benign, 1=attack)\"\"\"\n",
    "    binary_labels = []\n",
    "    for label in labels:\n",
    "        if isinstance(label, str):\n",
    "            if label.upper() == 'BENIGN':\n",
    "                binary_labels.append(0)\n",
    "            else:\n",
    "                binary_labels.append(1)\n",
    "        else:\n",
    "            # If numeric, assume 0 is benign\n",
    "            binary_labels.append(1 if label != 0 else 0)\n",
    "    return np.array(binary_labels)\n",
    "\n",
    "labels = create_binary_labels(data['Label'])\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(f\"\\nBinary label distribution: {dict(zip(unique, counts))}\")\n",
    "print(f\"Attack ratio: {counts[1]/len(labels):.4f}\")\n",
    "\n",
    "# ==============================\n",
    "# 2. Feature Engineering and Cleaning\n",
    "# ==============================\n",
    "print(\"\\n=== Feature Engineering ===\")\n",
    "\n",
    "# Get numeric columns\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'Label' in numeric_cols:\n",
    "    numeric_cols.remove('Label')\n",
    "\n",
    "print(f\"Number of numeric features: {len(numeric_cols)}\")\n",
    "\n",
    "X = data[numeric_cols].copy()\n",
    "\n",
    "# Check for problematic columns\n",
    "print(\"\\nChecking data quality...\")\n",
    "inf_counts = np.isinf(X).sum()\n",
    "nan_counts = X.isnull().sum()\n",
    "zero_var_cols = X.columns[X.var() == 0].tolist()\n",
    "\n",
    "print(f\"Columns with infinite values: {inf_counts[inf_counts > 0].shape[0]}\")\n",
    "print(f\"Columns with NaN values: {nan_counts[nan_counts > 0].shape[0]}\")\n",
    "print(f\"Zero variance columns: {len(zero_var_cols)}\")\n",
    "\n",
    "# Clean the data\n",
    "# Replace infinite values with NaN first\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Remove columns with too many missing values (>50%)\n",
    "missing_threshold = 0.5\n",
    "high_missing_cols = X.columns[X.isnull().sum() / len(X) > missing_threshold].tolist()\n",
    "if high_missing_cols:\n",
    "    print(f\"Removing columns with >{missing_threshold*100}% missing: {high_missing_cols}\")\n",
    "    X = X.drop(columns=high_missing_cols)\n",
    "\n",
    "# Remove zero variance columns\n",
    "if zero_var_cols:\n",
    "    remaining_zero_var = [col for col in zero_var_cols if col in X.columns]\n",
    "    if remaining_zero_var:\n",
    "        print(f\"Removing zero variance columns: {remaining_zero_var}\")\n",
    "        X = X.drop(columns=remaining_zero_var)\n",
    "\n",
    "# Fill remaining missing values with median\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Remove highly correlated features to reduce redundancy\n",
    "correlation_matrix = X.corr().abs()\n",
    "upper_triangle = correlation_matrix.where(\n",
    "    np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
    ")\n",
    "high_corr_cols = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]\n",
    "if high_corr_cols:\n",
    "    print(f\"Removing {len(high_corr_cols)} highly correlated features\")\n",
    "    X = X.drop(columns=high_corr_cols)\n",
    "\n",
    "print(f\"Final feature count: {X.shape[1]}\")\n",
    "\n",
    "# ==============================\n",
    "# 3. Scaling and Train-Test Split\n",
    "# ==============================\n",
    "print(\"\\n=== Scaling and Splitting ===\")\n",
    "\n",
    "# Use RobustScaler for better handling of outliers\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Check if scaling worked\n",
    "print(f\"Scaled data range: [{X_scaled.min():.3f}, {X_scaled.max():.3f}]\")\n",
    "print(f\"Scaled data mean: {X_scaled.mean():.3f}, std: {X_scaled.std():.3f}\")\n",
    "\n",
    "# Split the data BEFORE creating sequences\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_scaled, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(X_train)} (attack rate: {y_train.mean():.4f})\")\n",
    "print(f\"Val samples: {len(X_val)} (attack rate: {y_val.mean():.4f})\")\n",
    "print(f\"Test samples: {len(X_test)} (attack rate: {y_test.mean():.4f})\")\n",
    "\n",
    "# ==============================\n",
    "# 4. Baseline Model Check\n",
    "# ==============================\n",
    "print(\"\\n=== Baseline Model Check ===\")\n",
    "\n",
    "# Test with a simple Random Forest to see if the data is learnable\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_val)\n",
    "rf_prob = rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(f\"Random Forest - AUC: {roc_auc_score(y_val, rf_prob):.4f}\")\n",
    "print(f\"Random Forest - F1: {f1_score(y_val, rf_pred):.4f}\")\n",
    "\n",
    "if roc_auc_score(y_val, rf_prob) < 0.6:\n",
    "    print(\"WARNING: Even Random Forest performs poorly. Check your data and labels!\")\n",
    "\n",
    "# ==============================\n",
    "# 5. Create Sequences for LSTM\n",
    "# ==============================\n",
    "def create_sliding_windows(X, y, window_size=5, step=1):\n",
    "    \"\"\"Create sliding windows for time series\"\"\"\n",
    "    X_windows = []\n",
    "    y_windows = []\n",
    "    \n",
    "    for i in range(0, len(X) - window_size + 1, step):\n",
    "        X_windows.append(X[i:i + window_size])\n",
    "        # Use the label of the last sample in the window\n",
    "        y_windows.append(y[i + window_size - 1])\n",
    "    \n",
    "    return np.array(X_windows, dtype=np.float32), np.array(y_windows, dtype=np.float32)\n",
    "\n",
    "# Create sequences for each split\n",
    "window_size = 5  # Smaller window for faster training\n",
    "print(f\"\\nCreating sequences with window size: {window_size}\")\n",
    "\n",
    "X_train_seq, y_train_seq = create_sliding_windows(X_train, y_train, window_size)\n",
    "X_val_seq, y_val_seq = create_sliding_windows(X_val, y_val, window_size)\n",
    "X_test_seq, y_test_seq = create_sliding_windows(X_test, y_test, window_size)\n",
    "\n",
    "print(f\"Train sequences: {X_train_seq.shape}\")\n",
    "print(f\"Val sequences: {X_val_seq.shape}\")\n",
    "print(f\"Test sequences: {X_test_seq.shape}\")\n",
    "\n",
    "# ==============================\n",
    "# 6. Simple LSTM Model\n",
    "# ==============================\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32, num_layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_dim)\n",
    "        lstm_out, (hidden, cell) = self.lstm(x)\n",
    "        \n",
    "        # Use the last time step\n",
    "        last_output = lstm_out[:, -1, :]  # (batch_size, hidden_dim)\n",
    "        \n",
    "        # Apply dropout and classify\n",
    "        output = self.dropout(last_output)\n",
    "        logits = self.classifier(output)\n",
    "        \n",
    "        return logits.squeeze(-1)\n",
    "\n",
    "# ==============================\n",
    "# 7. Training Function with Debugging\n",
    "# ==============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "def train_lstm_model(X_train, y_train, X_val, y_val, \n",
    "                    hidden_dim=32, num_layers=1, dropout=0.2, \n",
    "                    lr=0.001, batch_size=64, epochs=20):\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SimpleLSTM(\n",
    "        input_dim=X_train.shape[2],\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout\n",
    "    ).to(device)\n",
    "    \n",
    "    # Calculate class weights\n",
    "    pos_weight = torch.FloatTensor([np.sum(y_train == 0) / np.sum(y_train == 1)]).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    \n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    val_aucs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_probs = []\n",
    "        val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X = batch_X.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "                \n",
    "                val_probs.extend(probs)\n",
    "                val_targets.extend(batch_y.numpy())\n",
    "        \n",
    "        val_probs = np.array(val_probs)\n",
    "        val_targets = np.array(val_targets)\n",
    "        \n",
    "        val_auc = roc_auc_score(val_targets, val_probs)\n",
    "        val_aucs.append(val_auc)\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch+1:2d}/{epochs}: Loss={avg_loss:.4f}, Val AUC={val_auc:.4f}\")\n",
    "    \n",
    "    return model, train_losses, val_aucs\n",
    "\n",
    "# ==============================\n",
    "# 8. Train and Evaluate\n",
    "# ==============================\n",
    "print(\"\\n=== Training LSTM Model ===\")\n",
    "\n",
    "# Train with simple parameters first\n",
    "model, train_losses, val_aucs = train_lstm_model(\n",
    "    X_train_seq, y_train_seq, X_val_seq, y_val_seq,\n",
    "    hidden_dim=64, num_layers=2, dropout=0.3,\n",
    "    lr=0.001, batch_size=32, epochs=25\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# 9. Final Evaluation\n",
    "# ==============================\n",
    "print(\"\\n=== Final Evaluation ===\")\n",
    "\n",
    "# Test evaluation\n",
    "test_dataset = TensorDataset(torch.FloatTensor(X_test_seq), torch.FloatTensor(y_test_seq))\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "test_probs = []\n",
    "test_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "        \n",
    "        test_probs.extend(probs)\n",
    "        test_targets.extend(batch_y.numpy())\n",
    "\n",
    "test_probs = np.array(test_probs)\n",
    "test_targets = np.array(test_targets)\n",
    "\n",
    "# Find best threshold\n",
    "thresholds = np.linspace(0.1, 0.9, 100)\n",
    "f1_scores = [f1_score(test_targets, (test_probs >= t).astype(int)) for t in thresholds]\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "y_pred = (test_probs >= best_threshold).astype(int)\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.3f}\")\n",
    "print(f\"Test AUC: {roc_auc_score(test_targets, test_probs):.4f}\")\n",
    "print(f\"Test PR-AUC: {average_precision_score(test_targets, test_probs):.4f}\")\n",
    "print(f\"Test F1: {f1_score(test_targets, y_pred):.4f}\")\n",
    "print(f\"Test Precision: {precision_score(test_targets, y_pred):.4f}\")\n",
    "print(f\"Test Recall: {recall_score(test_targets, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(test_targets, y_pred))\n",
    "\n",
    "# ==============================\n",
    "# 10. Visualization\n",
    "# ==============================\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Training history\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(val_aucs)\n",
    "plt.title('Validation AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# ROC Curve\n",
    "plt.subplot(1, 3, 3)\n",
    "fpr, tpr, _ = roc_curve(test_targets, test_probs)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc_score(test_targets, test_probs):.3f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "precision, recall, _ = precision_recall_curve(test_targets, test_probs)\n",
    "plt.plot(recall, precision, label=f'PR-AUC = {average_precision_score(test_targets, test_probs):.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# ==============================\n",
    "# 11. Simple Hyperparameter Tuning (if needed)\n",
    "# ==============================\n",
    "if roc_auc_score(test_targets, test_probs) < 0.7:\n",
    "    print(\"\\n=== Trying Different Hyperparameters ===\")\n",
    "    \n",
    "    best_auc = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    for hidden_dim in [32, 64, 128]:\n",
    "        for lr in [0.001, 0.005, 0.01]:\n",
    "            for dropout in [0.2, 0.3, 0.5]:\n",
    "                print(f\"Testing: hidden={hidden_dim}, lr={lr}, dropout={dropout}\")\n",
    "                \n",
    "                model_test, _, aucs = train_lstm_model(\n",
    "                    X_train_seq, y_train_seq, X_val_seq, y_val_seq,\n",
    "                    hidden_dim=hidden_dim, dropout=dropout, lr=lr,\n",
    "                    epochs=15\n",
    "                )\n",
    "                \n",
    "                final_auc = max(aucs)\n",
    "                if final_auc > best_auc:\n",
    "                    best_auc = final_auc\n",
    "                    best_params = {'hidden_dim': hidden_dim, 'lr': lr, 'dropout': dropout}\n",
    "                    \n",
    "                print(f\"Best AUC so far: {best_auc:.4f}\")\n",
    "    \n",
    "    print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "print(\"\\n=== Analysis Complete ===\")\n",
    "print(\"If AUC is still low (<0.7), consider:\")\n",
    "print(\"1. Check if your labels are correct\")\n",
    "print(\"2. Try different feature engineering\")\n",
    "print(\"3. Use a different model architecture\")\n",
    "print(\"4. Ensure your data has temporal structure suitable for LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a70d2",
   "metadata": {},
   "source": [
    "#Improved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e703d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-18 21:43:50,349] A new study created in memory with name: no-name-faa87d24-fe0e-4c39-88ff-38016beedab9\n",
      "[I 2025-08-18 21:43:50,350] Trial 0 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 3, 'dropout': 0.24680559213273096, 'lr': 0.00010255552094216992, 'batch_size': 64, 'use_attention': True, 'bidirectional': True, 'optimizer': 'adam', 'l2_reg': 3.549878832196506e-06}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,352] Trial 1 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.38355586841671385, 'lr': 9.505122659935192e-05, 'batch_size': 128, 'use_attention': True, 'bidirectional': False, 'optimizer': 'adamw', 'l2_reg': 3.247673570627449e-06, 'weight_decay': 1.3492834268013232e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,354] Trial 2 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.22930163420191518, 'lr': 0.0011679817513130801, 'batch_size': 128, 'use_attention': False, 'bidirectional': False, 'optimizer': 'adamw', 'l2_reg': 4.366473592979636e-05, 'weight_decay': 2.3426581058204037e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,355] Trial 3 finished with value: 0.0 and parameters: {'hidden_dim': 64, 'num_layers': 4, 'dropout': 0.3793699936433256, 'lr': 0.003489140632563016, 'batch_size': 64, 'use_attention': False, 'bidirectional': False, 'optimizer': 'adam', 'l2_reg': 4.247058562261871e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,357] Trial 4 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 4, 'dropout': 0.4316734307889972, 'lr': 0.00012485368572526373, 'batch_size': 64, 'use_attention': False, 'bidirectional': False, 'optimizer': 'adamw', 'l2_reg': 7.411299781083242e-05, 'weight_decay': 4.589824181495648e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,358] Trial 5 finished with value: 0.0 and parameters: {'hidden_dim': 256, 'num_layers': 4, 'dropout': 0.39126724140656394, 'lr': 0.0029743734066098857, 'batch_size': 128, 'use_attention': True, 'bidirectional': True, 'optimizer': 'adam', 'l2_reg': 1.1919481947918734e-06}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,361] Trial 6 finished with value: 0.0 and parameters: {'hidden_dim': 256, 'num_layers': 2, 'dropout': 0.35257120734941083, 'lr': 0.0032666526101138692, 'batch_size': 128, 'use_attention': True, 'bidirectional': True, 'optimizer': 'adam', 'l2_reg': 7.947147424653752e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,363] Trial 7 finished with value: 0.0 and parameters: {'hidden_dim': 64, 'num_layers': 4, 'dropout': 0.3618026725746952, 'lr': 0.002059919812302594, 'batch_size': 32, 'use_attention': False, 'bidirectional': False, 'optimizer': 'adamw', 'l2_reg': 1.7874463256238412e-05, 'weight_decay': 2.781093697926551e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,364] Trial 8 finished with value: 0.0 and parameters: {'hidden_dim': 256, 'num_layers': 2, 'dropout': 0.3556371865230098, 'lr': 0.001273526311669559, 'batch_size': 64, 'use_attention': False, 'bidirectional': True, 'optimizer': 'adamw', 'l2_reg': 3.2213437409123405e-05, 'weight_decay': 1.2675278269816288e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,365] Trial 9 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.3468358280832689, 'lr': 0.0046802700512426874, 'batch_size': 128, 'use_attention': False, 'bidirectional': False, 'optimizer': 'adam', 'l2_reg': 1.8658181360124843e-06}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,377] Trial 10 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 3, 'dropout': 0.20226419579488797, 'lr': 0.0002578580184886606, 'batch_size': 32, 'use_attention': True, 'bidirectional': True, 'optimizer': 'adam', 'l2_reg': 0.0006932432173673802}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,392] Trial 11 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 3, 'dropout': 0.26950011650012634, 'lr': 5.6024663039341656e-05, 'batch_size': 64, 'use_attention': True, 'bidirectional': True, 'optimizer': 'adamw', 'l2_reg': 5.433882726831596e-06, 'weight_decay': 0.00044149735004750845}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,406] Trial 12 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 3, 'dropout': 0.49331493318504516, 'lr': 5.720202390299527e-05, 'batch_size': 128, 'use_attention': True, 'bidirectional': True, 'optimizer': 'adamw', 'l2_reg': 4.801943379928181e-06, 'weight_decay': 0.00020046179107204468}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,418] Trial 13 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 3, 'dropout': 0.2839972925810914, 'lr': 0.00022516603081743143, 'batch_size': 64, 'use_attention': True, 'bidirectional': False, 'optimizer': 'adam', 'l2_reg': 8.134650578175102e-06}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,433] Trial 14 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.3003008261552386, 'lr': 0.0001304462711638156, 'batch_size': 32, 'use_attention': True, 'bidirectional': False, 'optimizer': 'adamw', 'l2_reg': 2.7293824917205915e-06, 'weight_decay': 9.236820328697209e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,448] Trial 15 finished with value: 0.0 and parameters: {'hidden_dim': 64, 'num_layers': 3, 'dropout': 0.43179983176226366, 'lr': 0.0004833225835869798, 'batch_size': 128, 'use_attention': True, 'bidirectional': True, 'optimizer': 'adam', 'l2_reg': 1.4760430642653317e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,461] Trial 16 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.3151245328315967, 'lr': 0.00010064495224861673, 'batch_size': 64, 'use_attention': True, 'bidirectional': True, 'optimizer': 'adamw', 'l2_reg': 0.00021793637623134229, 'weight_decay': 0.0007917897852165169}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,474] Trial 17 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 3, 'dropout': 0.24921666079316895, 'lr': 0.00033348540576202853, 'batch_size': 64, 'use_attention': True, 'bidirectional': False, 'optimizer': 'adam', 'l2_reg': 1.0030274123877447e-06}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,490] Trial 18 finished with value: 0.0 and parameters: {'hidden_dim': 64, 'num_layers': 2, 'dropout': 0.4176628899086644, 'lr': 8.913273048870739e-05, 'batch_size': 128, 'use_attention': True, 'bidirectional': False, 'optimizer': 'adamw', 'l2_reg': 2.6725634780780354e-06, 'weight_decay': 1.2794510354967239e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,504] Trial 19 finished with value: 0.0 and parameters: {'hidden_dim': 256, 'num_layers': 3, 'dropout': 0.48088130164599696, 'lr': 0.00018103440307971539, 'batch_size': 32, 'use_attention': True, 'bidirectional': True, 'optimizer': 'adam', 'l2_reg': 1.0131948806832365e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,517] Trial 20 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 3, 'dropout': 0.3303909244567196, 'lr': 0.0006250676834166352, 'batch_size': 128, 'use_attention': True, 'bidirectional': True, 'optimizer': 'adamw', 'l2_reg': 4.3832007518954685e-06, 'weight_decay': 9.582011961973034e-05}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Advanced LSTM Optimization ===\n",
      "Running advanced hyperparameter optimization...\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-18 21:43:50,533] Trial 21 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.20760138184617546, 'lr': 0.0010388421278803004, 'batch_size': 128, 'use_attention': False, 'bidirectional': False, 'optimizer': 'adamw', 'l2_reg': 8.894323662434194e-05, 'weight_decay': 2.8955939584947182e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,550] Trial 22 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.23991507864034825, 'lr': 0.0009550591529559523, 'batch_size': 128, 'use_attention': False, 'bidirectional': False, 'optimizer': 'adamw', 'l2_reg': 0.00020628543305188098, 'weight_decay': 1.0533628074120723e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,566] Trial 23 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.23606686839418584, 'lr': 0.0005346827298084538, 'batch_size': 128, 'use_attention': False, 'bidirectional': False, 'optimizer': 'adamw', 'l2_reg': 1.7028674010213412e-05, 'weight_decay': 3.0193842779534562e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-08-18 21:43:50,583] Trial 24 finished with value: 0.0 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.2581013251651953, 'lr': 0.0015740875081116416, 'batch_size': 128, 'use_attention': False, 'bidirectional': False, 'optimizer': 'adamw', 'l2_reg': 4.1824896147304134e-05, 'weight_decay': 5.5752381734372e-05}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Trial failed: name 'X_train_seq' is not defined\n",
      "Best hyperparameters: {'hidden_dim': 128, 'num_layers': 3, 'dropout': 0.24680559213273096, 'lr': 0.00010255552094216992, 'batch_size': 64, 'use_attention': True, 'bidirectional': True, 'optimizer': 'adam', 'l2_reg': 3.549878832196506e-06}\n",
      "Best CV F1 score: 0.0\n",
      "\n",
      "Training final advanced model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 383\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining final advanced model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    381\u001b[39m best_params = study.best_params\n\u001b[32m    382\u001b[39m final_model, train_losses, val_aucs, val_f1s = train_advanced_lstm(\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m     \u001b[43mX_train_seq\u001b[49m, y_train_seq, X_val_seq, y_val_seq, \n\u001b[32m    384\u001b[39m     best_params, epochs=\u001b[32m40\u001b[39m\n\u001b[32m    385\u001b[39m )\n\u001b[32m    387\u001b[39m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[32m    388\u001b[39m \u001b[38;5;66;03m# 6. Comprehensive Evaluation\u001b[39;00m\n\u001b[32m    389\u001b[39m \u001b[38;5;66;03m# ==============================\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Comprehensive Evaluation ===\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_seq' is not defined"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Advanced LSTM Optimizations for CICIDS2017\n",
    "# Based on excellent baseline results (AUC: 0.9915)\n",
    "# ==============================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, roc_curve, precision_recall_curve,\n",
    "    classification_report\n",
    ")\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==============================\n",
    "# 1. Advanced LSTM Architecture\n",
    "# ==============================\n",
    "class AdvancedLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2, dropout=0.3, \n",
    "                 use_attention=True, bidirectional=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.use_attention = use_attention\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        \n",
    "        lstm_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        \n",
    "        # Attention mechanism\n",
    "        if use_attention:\n",
    "            self.attention = nn.MultiheadAttention(\n",
    "                embed_dim=lstm_output_dim,\n",
    "                num_heads=4,\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "            )\n",
    "        \n",
    "        # Classification head with residual connection\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_output_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # LSTM forward pass\n",
    "        lstm_out, (hidden, cell) = self.lstm(x)\n",
    "        \n",
    "        if self.use_attention:\n",
    "            # Apply attention to all time steps\n",
    "            attended_out, attention_weights = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "            # Use mean of attended outputs\n",
    "            features = attended_out.mean(dim=1)\n",
    "        else:\n",
    "            # Use last time step\n",
    "            features = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        return logits.squeeze(-1)\n",
    "\n",
    "# ==============================\n",
    "# 2. Advanced Training with Cross-Validation\n",
    "# ==============================\n",
    "def train_advanced_lstm(X_train, y_train, X_val, y_val, params, epochs=30):\n",
    "    \n",
    "    # Create weighted sampler for balanced training\n",
    "    class_counts = Counter(y_train)\n",
    "    class_weights = {0: 1.0, 1: class_counts[0] / class_counts[1]}\n",
    "    sample_weights = [class_weights[int(label)] for label in y_train]\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n",
    "    \n",
    "    # Weighted sampler for balanced batches\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], sampler=sampler)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = AdvancedLSTM(\n",
    "        input_dim=X_train.shape[2],\n",
    "        hidden_dim=params['hidden_dim'],\n",
    "        num_layers=params['num_layers'],\n",
    "        dropout=params['dropout'],\n",
    "        use_attention=params.get('use_attention', True),\n",
    "        bidirectional=params.get('bidirectional', True)\n",
    "    ).to(device)\n",
    "    \n",
    "    # Advanced optimizer with weight decay\n",
    "    if params.get('optimizer') == 'adamw':\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), \n",
    "            lr=params['lr'], \n",
    "            weight_decay=params.get('weight_decay', 1e-4)\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=params['lr'] * 3,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.3\n",
    "    )\n",
    "    \n",
    "    # Loss function with class weights\n",
    "    pos_weight = torch.FloatTensor([class_counts[0] / class_counts[1]]).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    \n",
    "    # Training metrics\n",
    "    train_losses = []\n",
    "    val_aucs = []\n",
    "    val_f1s = []\n",
    "    best_val_f1 = 0\n",
    "    best_model_state = None\n",
    "    patience = 7\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            # Add L2 regularization manually if needed\n",
    "            if params.get('l2_reg', 0) > 0:\n",
    "                l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "                loss += params['l2_reg'] * l2_norm\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_probs = []\n",
    "        val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X = batch_X.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "                \n",
    "                val_probs.extend(probs)\n",
    "                val_targets.extend(batch_y.numpy())\n",
    "        \n",
    "        val_probs = np.array(val_probs)\n",
    "        val_targets = np.array(val_targets)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_auc = roc_auc_score(val_targets, val_probs)\n",
    "        \n",
    "        # Find best threshold for F1\n",
    "        thresholds = np.linspace(0.1, 0.9, 50)\n",
    "        f1_scores = [f1_score(val_targets, (val_probs >= t).astype(int)) for t in thresholds]\n",
    "        best_f1 = max(f1_scores)\n",
    "        \n",
    "        val_aucs.append(val_auc)\n",
    "        val_f1s.append(best_f1)\n",
    "        \n",
    "        # Early stopping based on F1 score\n",
    "        if best_f1 > best_val_f1:\n",
    "            best_val_f1 = best_f1\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch+1:2d}/{epochs}: Loss={avg_loss:.4f}, \"\n",
    "                  f\"Val AUC={val_auc:.4f}, Val F1={best_f1:.4f}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, train_losses, val_aucs, val_f1s\n",
    "\n",
    "# ==============================\n",
    "# 3. Advanced Hyperparameter Optimization\n",
    "# ==============================\n",
    "def advanced_objective(trial):\n",
    "    params = {\n",
    "        'hidden_dim': trial.suggest_categorical('hidden_dim', [64, 128, 256]),\n",
    "        'num_layers': trial.suggest_int('num_layers', 2, 4),\n",
    "        'dropout': trial.suggest_float('dropout', 0.2, 0.5),\n",
    "        'lr': trial.suggest_float('lr', 5e-5, 5e-3, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [32, 64, 128]),\n",
    "        'use_attention': trial.suggest_categorical('use_attention', [True, False]),\n",
    "        'bidirectional': trial.suggest_categorical('bidirectional', [True, False]),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'adamw']),\n",
    "        'l2_reg': trial.suggest_float('l2_reg', 1e-6, 1e-3, log=True),\n",
    "    }\n",
    "    \n",
    "    if params['optimizer'] == 'adamw':\n",
    "        params['weight_decay'] = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    \n",
    "    try:\n",
    "        # Use cross-validation for more robust evaluation\n",
    "        kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        cv_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in kf.split(X_train_seq, y_train_seq):\n",
    "            X_cv_train, X_cv_val = X_train_seq[train_idx], X_train_seq[val_idx]\n",
    "            y_cv_train, y_cv_val = y_train_seq[train_idx], y_train_seq[val_idx]\n",
    "            \n",
    "            model, _, _, val_f1s = train_advanced_lstm(\n",
    "                X_cv_train, y_cv_train, X_cv_val, y_cv_val, \n",
    "                params, epochs=15\n",
    "            )\n",
    "            \n",
    "            cv_scores.append(max(val_f1s))\n",
    "        \n",
    "        return np.mean(cv_scores)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# ==============================\n",
    "# 4. Model Interpretability\n",
    "# ==============================\n",
    "def analyze_feature_importance(model, X_sample, feature_names):\n",
    "    \"\"\"Analyze which features are most important for predictions\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Use gradient-based feature importance\n",
    "    X_tensor = torch.FloatTensor(X_sample[:100]).to(device)  # Use subset for speed\n",
    "    X_tensor.requires_grad_(True)\n",
    "    \n",
    "    outputs = model(X_tensor)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    outputs.sum().backward()\n",
    "    gradients = X_tensor.grad.abs().mean(dim=[0, 1]).cpu().numpy()\n",
    "    \n",
    "    # Create feature importance DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': gradients\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "def plot_advanced_results(train_losses, val_aucs, val_f1s, test_results):\n",
    "    \"\"\"Create comprehensive result plots\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # Training history\n",
    "    axes[0, 0].plot(train_losses)\n",
    "    axes[0, 0].set_title('Training Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].plot(val_aucs, label='AUC', color='blue')\n",
    "    axes[0, 1].plot(val_f1s, label='F1', color='red')\n",
    "    axes[0, 1].set_title('Validation Metrics')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Score')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ROC and PR curves\n",
    "    fpr, tpr, _ = roc_curve(test_results['y_true'], test_results['y_prob'])\n",
    "    axes[0, 2].plot(fpr, tpr, label=f'AUC = {test_results[\"auc\"]:.4f}')\n",
    "    axes[0, 2].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "    axes[0, 2].set_title('ROC Curve')\n",
    "    axes[0, 2].set_xlabel('False Positive Rate')\n",
    "    axes[0, 2].set_ylabel('True Positive Rate')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(test_results['y_true'], test_results['y_prob'])\n",
    "    axes[1, 0].plot(recall, precision, label=f'PR-AUC = {test_results[\"pr_auc\"]:.4f}')\n",
    "    axes[1, 0].set_title('Precision-Recall Curve')\n",
    "    axes[1, 0].set_xlabel('Recall')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(test_results['y_true'], test_results['y_pred'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=axes[1, 1], cmap='Blues')\n",
    "    axes[1, 1].set_title('Confusion Matrix')\n",
    "    axes[1, 1].set_xlabel('Predicted')\n",
    "    axes[1, 1].set_ylabel('Actual')\n",
    "    \n",
    "    # Threshold analysis\n",
    "    thresholds = np.linspace(0.1, 0.9, 100)\n",
    "    f1_scores = [f1_score(test_results['y_true'], (test_results['y_prob'] >= t).astype(int)) \n",
    "                 for t in thresholds]\n",
    "    axes[1, 2].plot(thresholds, f1_scores)\n",
    "    axes[1, 2].axvline(x=test_results['best_threshold'], color='red', linestyle='--')\n",
    "    axes[1, 2].set_title('F1 Score vs Threshold')\n",
    "    axes[1, 2].set_xlabel('Threshold')\n",
    "    axes[1, 2].set_ylabel('F1 Score')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ==============================\n",
    "# 5. Run Advanced Optimization\n",
    "# ==============================\n",
    "print(\"\\n=== Advanced LSTM Optimization ===\")\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "print(\"Running advanced hyperparameter optimization...\")\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "study.optimize(advanced_objective, n_trials=25, timeout=7200)  # 2 hour timeout\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best CV F1 score:\", study.best_value)\n",
    "\n",
    "# Train final model with best parameters\n",
    "print(\"\\nTraining final advanced model...\")\n",
    "best_params = study.best_params\n",
    "final_model, train_losses, val_aucs, val_f1s = train_advanced_lstm(\n",
    "    X_train_seq, y_train_seq, X_val_seq, y_val_seq, \n",
    "    best_params, epochs=40\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# 6. Comprehensive Evaluation\n",
    "# ==============================\n",
    "print(\"\\n=== Comprehensive Evaluation ===\")\n",
    "\n",
    "# Test evaluation\n",
    "test_dataset = TensorDataset(torch.FloatTensor(X_test_seq), torch.FloatTensor(y_test_seq))\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "final_model.eval()\n",
    "test_probs = []\n",
    "test_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        outputs = final_model(batch_X)\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "        \n",
    "        test_probs.extend(probs)\n",
    "        test_targets.extend(batch_y.numpy())\n",
    "\n",
    "test_probs = np.array(test_probs)\n",
    "test_targets = np.array(test_targets)\n",
    "\n",
    "# Find optimal threshold\n",
    "thresholds = np.linspace(0.1, 0.9, 100)\n",
    "f1_scores = [f1_score(test_targets, (test_probs >= t).astype(int)) for t in thresholds]\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_final = (test_probs >= best_threshold).astype(int)\n",
    "\n",
    "# Calculate all metrics\n",
    "test_results = {\n",
    "    'y_true': test_targets,\n",
    "    'y_prob': test_probs,\n",
    "    'y_pred': y_pred_final,\n",
    "    'auc': roc_auc_score(test_targets, test_probs),\n",
    "    'pr_auc': average_precision_score(test_targets, test_probs),\n",
    "    'f1': f1_score(test_targets, y_pred_final),\n",
    "    'precision': precision_score(test_targets, y_pred_final),\n",
    "    'recall': recall_score(test_targets, y_pred_final),\n",
    "    'best_threshold': best_threshold\n",
    "}\n",
    "\n",
    "print(f\"Advanced Model Results:\")\n",
    "print(f\"AUC: {test_results['auc']:.4f}\")\n",
    "print(f\"PR-AUC: {test_results['pr_auc']:.4f}\")\n",
    "print(f\"F1: {test_results['f1']:.4f}\")\n",
    "print(f\"Precision: {test_results['precision']:.4f}\")\n",
    "print(f\"Recall: {test_results['recall']:.4f}\")\n",
    "print(f\"Best Threshold: {test_results['best_threshold']:.4f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(test_targets, y_pred_final, \n",
    "                          target_names=['Benign', 'Attack']))\n",
    "\n",
    "# ==============================\n",
    "# 7. Model Analysis\n",
    "# ==============================\n",
    "print(\"\\n=== Model Analysis ===\")\n",
    "\n",
    "# Feature importance analysis\n",
    "if len(numeric_cols) == X_test_seq.shape[2]:  # Make sure dimensions match\n",
    "    importance_df = analyze_feature_importance(final_model, X_test_seq, numeric_cols)\n",
    "    print(\"Top 10 Most Important Features:\")\n",
    "    print(importance_df.head(10))\n",
    "\n",
    "# Plot comprehensive results\n",
    "plot_advanced_results(train_losses, val_aucs, val_f1s, test_results)\n",
    "\n",
    "# Compare with original simple model\n",
    "print(f\"\\n=== Performance Comparison ===\")\n",
    "print(f\"Original LSTM - AUC: 0.9915, F1: 0.8939\")\n",
    "print(f\"Advanced LSTM - AUC: {test_results['auc']:.4f}, F1: {test_results['f1']:.4f}\")\n",
    "\n",
    "improvement_auc = test_results['auc'] - 0.9915\n",
    "improvement_f1 = test_results['f1'] - 0.8939\n",
    "print(f\"AUC Improvement: {improvement_auc:+.4f}\")\n",
    "print(f\"F1 Improvement: {improvement_f1:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f720df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "=== Advanced LSTM Optimization for CICIDS2017 ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datadf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 630\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 483\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Advanced LSTM Optimization for CICIDS2017 ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# Load and preprocess data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m df, feature_names = \u001b[43mdatadf\u001b[49m, ftnames\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# Prepare features and labels\u001b[39;00m\n\u001b[32m    486\u001b[39m X = df.values\n",
      "\u001b[31mNameError\u001b[39m: name 'datadf' is not defined"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Advanced LSTM Optimizations for CICIDS2017\n",
    "# Based on excellent baseline results (AUC: 0.9915)\n",
    "# ==============================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, roc_curve, precision_recall_curve,\n",
    "    classification_report\n",
    ")\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ==============================\n",
    "# 0. Data Loading and Preprocessing\n",
    "# ==============================\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"\n",
    "    Load CICIDS2017 dataset and prepare it for LSTM training\n",
    "    Note: Replace this with your actual data loading logic\n",
    "    \"\"\"\n",
    "    print(\"Loading CICIDS2017 dataset...\")\n",
    "    \n",
    "    # This is a placeholder - replace with your actual data loading\n",
    "    # For demonstration, I'll create a synthetic dataset that mimics CICIDS2017 structure\n",
    "    print(\"Note: Using synthetic data for demonstration. Replace with actual CICIDS2017 data.\")\n",
    "    \n",
    "    # Generate synthetic data that mimics CICIDS2017 characteristics\n",
    "    np.random.seed(42)\n",
    "    n_samples = 10000\n",
    "    n_features = 78  # Typical number of features in CICIDS2017\n",
    "    \n",
    "    # Create synthetic features\n",
    "    X_synthetic = np.random.randn(n_samples, n_features)\n",
    "    # Add some correlation patterns to make it more realistic\n",
    "    X_synthetic[:, 1] = X_synthetic[:, 0] * 0.7 + np.random.randn(n_samples) * 0.3\n",
    "    X_synthetic[:, 2] = X_synthetic[:, 0] * 0.5 + X_synthetic[:, 1] * 0.3 + np.random.randn(n_samples) * 0.2\n",
    "    \n",
    "    # Create synthetic binary labels (0: benign, 1: attack)\n",
    "    # Make attacks correlated with certain features\n",
    "    attack_prob = 1 / (1 + np.exp(-(X_synthetic[:, 0] + X_synthetic[:, 1] * 0.5 - 0.5)))\n",
    "    y_synthetic = np.random.binomial(1, attack_prob)\n",
    "    \n",
    "    # Create feature names\n",
    "    feature_names = [f'feature_{i}' for i in range(n_features)]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(X_synthetic, columns=feature_names)\n",
    "    df['Label'] = y_synthetic\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Attack samples: {sum(y_synthetic)} ({sum(y_synthetic)/len(y_synthetic)*100:.1f}%)\")\n",
    "    \n",
    "    print(df.shape)\n",
    "    return df, feature_names\n",
    "\n",
    "def prepare_lstm_sequences(X, y, sequence_length=10):\n",
    "    \"\"\"\n",
    "    Convert tabular data to sequences for LSTM training\n",
    "    \"\"\"\n",
    "    print(f\"Creating sequences of length {sequence_length}...\")\n",
    "    \n",
    "    # If we have fewer samples than sequence_length, use available samples\n",
    "    if len(X) < sequence_length:\n",
    "        sequence_length = len(X)\n",
    "        print(f\"Adjusted sequence length to {sequence_length} due to limited data\")\n",
    "    \n",
    "    X_sequences = []\n",
    "    y_sequences = []\n",
    "    \n",
    "    # Create overlapping sequences\n",
    "    for i in range(len(X) - sequence_length + 1):\n",
    "        X_sequences.append(X[i:i + sequence_length])\n",
    "        # Use the label of the last sample in the sequence\n",
    "        y_sequences.append(y[i + sequence_length - 1])\n",
    "    \n",
    "    X_sequences = np.array(X_sequences)\n",
    "    y_sequences = np.array(y_sequences)\n",
    "    \n",
    "    print(f\"Created {len(X_sequences)} sequences\")\n",
    "    print(f\"Sequence shape: {X_sequences.shape}\")\n",
    "    \n",
    "    return X_sequences, y_sequences\n",
    "\n",
    "# ==============================\n",
    "# 1. Advanced LSTM Architecture\n",
    "# ==============================\n",
    "class AdvancedLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2, dropout=0.3, \n",
    "                 use_attention=True, bidirectional=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.use_attention = use_attention\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        \n",
    "        lstm_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "        \n",
    "        # Attention mechanism\n",
    "        if use_attention:\n",
    "            self.attention = nn.MultiheadAttention(\n",
    "                embed_dim=lstm_output_dim,\n",
    "                num_heads=4,\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "            )\n",
    "        \n",
    "        # Classification head with residual connection\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_output_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # LSTM forward pass\n",
    "        lstm_out, (hidden, cell) = self.lstm(x)\n",
    "        \n",
    "        if self.use_attention:\n",
    "            # Apply attention to all time steps\n",
    "            attended_out, attention_weights = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "            # Use mean of attended outputs\n",
    "            features = attended_out.mean(dim=1)\n",
    "        else:\n",
    "            # Use last time step\n",
    "            features = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        return logits.squeeze(-1)\n",
    "\n",
    "# ==============================\n",
    "# 2. Advanced Training with Cross-Validation\n",
    "# ==============================\n",
    "def train_advanced_lstm(X_train, y_train, X_val, y_val, params, epochs=30):\n",
    "    \n",
    "    # Create weighted sampler for balanced training\n",
    "    class_counts = Counter(y_train)\n",
    "    if len(class_counts) < 2:\n",
    "        # Handle case where we only have one class\n",
    "        class_weights = {0: 1.0, 1: 1.0}\n",
    "    else:\n",
    "        class_weights = {0: 1.0, 1: class_counts[0] / class_counts[1] if class_counts[1] > 0 else 1.0}\n",
    "    \n",
    "    sample_weights = [class_weights[int(label)] for label in y_train]\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n",
    "    \n",
    "    # Weighted sampler for balanced batches\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], sampler=sampler)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = AdvancedLSTM(\n",
    "        input_dim=X_train.shape[2],\n",
    "        hidden_dim=params['hidden_dim'],\n",
    "        num_layers=params['num_layers'],\n",
    "        dropout=params['dropout'],\n",
    "        use_attention=params.get('use_attention', True),\n",
    "        bidirectional=params.get('bidirectional', True)\n",
    "    ).to(device)\n",
    "    \n",
    "    # Advanced optimizer with weight decay\n",
    "    if params.get('optimizer') == 'adamw':\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), \n",
    "            lr=params['lr'], \n",
    "            weight_decay=params.get('weight_decay', 1e-4)\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=params['lr'] * 3,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.3\n",
    "    )\n",
    "    \n",
    "    # Loss function with class weights\n",
    "    if len(class_counts) > 1 and class_counts[1] > 0:\n",
    "        pos_weight = torch.FloatTensor([class_counts[0] / class_counts[1]]).to(device)\n",
    "    else:\n",
    "        pos_weight = torch.FloatTensor([1.0]).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    \n",
    "    # Training metrics\n",
    "    train_losses = []\n",
    "    val_aucs = []\n",
    "    val_f1s = []\n",
    "    best_val_f1 = 0\n",
    "    best_model_state = None\n",
    "    patience = 7\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            # Add L2 regularization manually if needed\n",
    "            if params.get('l2_reg', 0) > 0:\n",
    "                l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "                loss += params['l2_reg'] * l2_norm\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_probs = []\n",
    "        val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X = batch_X.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "                \n",
    "                val_probs.extend(probs)\n",
    "                val_targets.extend(batch_y.numpy())\n",
    "        \n",
    "        val_probs = np.array(val_probs)\n",
    "        val_targets = np.array(val_targets)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if len(np.unique(val_targets)) > 1:\n",
    "            val_auc = roc_auc_score(val_targets, val_probs)\n",
    "        else:\n",
    "            val_auc = 0.5  # Default value when only one class present\n",
    "        \n",
    "        # Find best threshold for F1\n",
    "        thresholds = np.linspace(0.1, 0.9, 50)\n",
    "        f1_scores = []\n",
    "        for t in thresholds:\n",
    "            try:\n",
    "                f1 = f1_score(val_targets, (val_probs >= t).astype(int))\n",
    "                f1_scores.append(f1)\n",
    "            except:\n",
    "                f1_scores.append(0.0)\n",
    "        best_f1 = max(f1_scores) if f1_scores else 0.0\n",
    "        \n",
    "        val_aucs.append(val_auc)\n",
    "        val_f1s.append(best_f1)\n",
    "        \n",
    "        # Early stopping based on F1 score\n",
    "        if best_f1 > best_val_f1:\n",
    "            best_val_f1 = best_f1\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch+1:2d}/{epochs}: Loss={avg_loss:.4f}, \"\n",
    "                  f\"Val AUC={val_auc:.4f}, Val F1={best_f1:.4f}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, train_losses, val_aucs, val_f1s\n",
    "\n",
    "# ==============================\n",
    "# 3. Advanced Hyperparameter Optimization\n",
    "# ==============================\n",
    "def advanced_objective(trial, X_train_seq, y_train_seq):\n",
    "    params = {\n",
    "        'hidden_dim': trial.suggest_categorical('hidden_dim', [64, 128, 256]),\n",
    "        'num_layers': trial.suggest_int('num_layers', 2, 4),\n",
    "        'dropout': trial.suggest_float('dropout', 0.2, 0.5),\n",
    "        'lr': trial.suggest_float('lr', 5e-5, 5e-3, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [32, 64, 128]),\n",
    "        'use_attention': trial.suggest_categorical('use_attention', [True, False]),\n",
    "        'bidirectional': trial.suggest_categorical('bidirectional', [True, False]),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'adamw']),\n",
    "        'l2_reg': trial.suggest_float('l2_reg', 1e-6, 1e-3, log=True),\n",
    "    }\n",
    "    \n",
    "    if params['optimizer'] == 'adamw':\n",
    "        params['weight_decay'] = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    \n",
    "    try:\n",
    "        # Use cross-validation for more robust evaluation\n",
    "        kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        cv_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in kf.split(X_train_seq, y_train_seq):\n",
    "            X_cv_train, X_cv_val = X_train_seq[train_idx], X_train_seq[val_idx]\n",
    "            y_cv_train, y_cv_val = y_train_seq[train_idx], y_train_seq[val_idx]\n",
    "            \n",
    "            model, _, _, val_f1s = train_advanced_lstm(\n",
    "                X_cv_train, y_cv_train, X_cv_val, y_cv_val, \n",
    "                params, epochs=15\n",
    "            )\n",
    "            \n",
    "            cv_scores.append(max(val_f1s))\n",
    "        \n",
    "        return np.mean(cv_scores)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# ==============================\n",
    "# 4. Model Interpretability - FIXED VERSION\n",
    "# ==============================\n",
    "def analyze_feature_importance(model, X_sample, feature_names):\n",
    "    \"\"\"Analyze which features are most important for predictions\"\"\"\n",
    "    # Store original model state\n",
    "    original_training_state = model.training\n",
    "    \n",
    "    # Set model to training mode for gradient computation\n",
    "    model.train()\n",
    "    \n",
    "    try:\n",
    "        # Use gradient-based feature importance\n",
    "        X_tensor = torch.FloatTensor(X_sample[:100]).to(device)  # Use subset for speed\n",
    "        X_tensor.requires_grad_(True)\n",
    "        \n",
    "        outputs = model(X_tensor)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        outputs.sum().backward()\n",
    "        gradients = X_tensor.grad.abs().mean(dim=[0, 1]).cpu().numpy()\n",
    "        \n",
    "        # Create feature importance DataFrame\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': gradients\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        return importance_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in feature importance analysis: {e}\")\n",
    "        # Return dummy DataFrame in case of error\n",
    "        return pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': np.zeros(len(feature_names))\n",
    "        })\n",
    "    \n",
    "    finally:\n",
    "        # Restore original model state\n",
    "        model.train(original_training_state)\n",
    "\n",
    "def plot_advanced_results(train_losses, val_aucs, val_f1s, test_results):\n",
    "    \"\"\"Create comprehensive result plots\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # Training history\n",
    "    axes[0, 0].plot(train_losses)\n",
    "    axes[0, 0].set_title('Training Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].plot(val_aucs, label='AUC', color='blue')\n",
    "    axes[0, 1].plot(val_f1s, label='F1', color='red')\n",
    "    axes[0, 1].set_title('Validation Metrics')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Score')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ROC and PR curves\n",
    "    fpr, tpr, _ = roc_curve(test_results['y_true'], test_results['y_prob'])\n",
    "    axes[0, 2].plot(fpr, tpr, label=f'AUC = {test_results[\"auc\"]:.4f}')\n",
    "    axes[0, 2].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "    axes[0, 2].set_title('ROC Curve')\n",
    "    axes[0, 2].set_xlabel('False Positive Rate')\n",
    "    axes[0, 2].set_ylabel('True Positive Rate')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(test_results['y_true'], test_results['y_prob'])\n",
    "    axes[1, 0].plot(recall, precision, label=f'PR-AUC = {test_results[\"pr_auc\"]:.4f}')\n",
    "    axes[1, 0].set_title('Precision-Recall Curve')\n",
    "    axes[1, 0].set_xlabel('Recall')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(test_results['y_true'], test_results['y_pred'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=axes[1, 1], cmap='Blues')\n",
    "    axes[1, 1].set_title('Confusion Matrix')\n",
    "    axes[1, 1].set_xlabel('Predicted')\n",
    "    axes[1, 1].set_ylabel('Actual')\n",
    "    \n",
    "    # Threshold analysis\n",
    "    thresholds = np.linspace(0.1, 0.9, 100)\n",
    "    f1_scores = []\n",
    "    for t in thresholds:\n",
    "        try:\n",
    "            f1 = f1_score(test_results['y_true'], (test_results['y_prob'] >= t).astype(int))\n",
    "            f1_scores.append(f1)\n",
    "        except:\n",
    "            f1_scores.append(0.0)\n",
    "    \n",
    "    axes[1, 2].plot(thresholds, f1_scores)\n",
    "    axes[1, 2].axvline(x=test_results['best_threshold'], color='red', linestyle='--')\n",
    "    axes[1, 2].set_title('F1 Score vs Threshold')\n",
    "    axes[1, 2].set_xlabel('Threshold')\n",
    "    axes[1, 2].set_ylabel('F1 Score')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ==============================\n",
    "# 5. Main Execution\n",
    "# ==============================\n",
    "def main():\n",
    "    print(\"\\n=== Advanced LSTM Optimization for CICIDS2017 ===\")\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    df, feature_names = datadf, ftnames\n",
    "      \n",
    "    # Prepare features and labels\n",
    "    X = df.values\n",
    "    y = df['Label'].values\n",
    "    \n",
    "    # Scale features\n",
    "    print(\"Scaling features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split data\n",
    "    print(\"Splitting data...\")\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X_scaled, y, test_size=0.4, random_state=42, stratify=y\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    # Create sequences for LSTM\n",
    "    print(\"Creating sequences for LSTM...\")\n",
    "    sequence_length = min(10, len(X_train) // 2)  # Adaptive sequence length\n",
    "    \n",
    "    X_train_seq, y_train_seq = prepare_lstm_sequences(X_train, y_train, sequence_length)\n",
    "    X_val_seq, y_val_seq = prepare_lstm_sequences(X_val, y_val, sequence_length)\n",
    "    X_test_seq, y_test_seq = prepare_lstm_sequences(X_test, y_test, sequence_length)\n",
    "    \n",
    "    print(f\"Training sequences: {X_train_seq.shape}\")\n",
    "    print(f\"Validation sequences: {X_val_seq.shape}\")\n",
    "    print(f\"Test sequences: {X_test_seq.shape}\")\n",
    "    \n",
    "    # Run hyperparameter optimization\n",
    "    print(\"\\nRunning advanced hyperparameter optimization...\")\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "        sampler=optuna.samplers.TPESampler(seed=42)\n",
    "    )\n",
    "    \n",
    "    # Create objective function with data\n",
    "    def objective(trial):\n",
    "        return advanced_objective(trial, X_train_seq, y_train_seq)\n",
    "    \n",
    "    study.optimize(objective, n_trials=25, timeout=7200)  # 2 hour timeout\n",
    "    \n",
    "    print(\"Best hyperparameters:\", study.best_params)\n",
    "    print(\"Best CV F1 score:\", study.best_value)\n",
    "    \n",
    "    # Train final model with best parameters\n",
    "    print(\"\\nTraining final advanced model...\")\n",
    "    best_params = study.best_params\n",
    "    final_model, train_losses, val_aucs, val_f1s = train_advanced_lstm(\n",
    "        X_train_seq, y_train_seq, X_val_seq, y_val_seq, \n",
    "        best_params, epochs=40\n",
    "    )\n",
    "    \n",
    "    # ==============================\n",
    "    # 6. Comprehensive Evaluation\n",
    "    # ==============================\n",
    "    print(\"\\n=== Comprehensive Evaluation ===\")\n",
    "    \n",
    "    # Test evaluation\n",
    "    test_dataset = TensorDataset(torch.FloatTensor(X_test_seq), torch.FloatTensor(y_test_seq))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    final_model.eval()\n",
    "    test_probs = []\n",
    "    test_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            outputs = final_model(batch_X)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            \n",
    "            test_probs.extend(probs)\n",
    "            test_targets.extend(batch_y.numpy())\n",
    "    \n",
    "    test_probs = np.array(test_probs)\n",
    "    test_targets = np.array(test_targets)\n",
    "    \n",
    "    # Find optimal threshold\n",
    "    thresholds = np.linspace(0.1, 0.9, 100)\n",
    "    f1_scores = []\n",
    "    for t in thresholds:\n",
    "        try:\n",
    "            f1 = f1_score(test_targets, (test_probs >= t).astype(int))\n",
    "            f1_scores.append(f1)\n",
    "        except:\n",
    "            f1_scores.append(0.0)\n",
    "    \n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    y_pred_final = (test_probs >= best_threshold).astype(int)\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    test_results = {\n",
    "        'y_true': test_targets,\n",
    "        'y_prob': test_probs,\n",
    "        'y_pred': y_pred_final,\n",
    "        'auc': roc_auc_score(test_targets, test_probs) if len(np.unique(test_targets)) > 1 else 0.5,\n",
    "        'pr_auc': average_precision_score(test_targets, test_probs) if len(np.unique(test_targets)) > 1 else 0.5,\n",
    "        'f1': f1_score(test_targets, y_pred_final),\n",
    "        'precision': precision_score(test_targets, y_pred_final, zero_division=0),\n",
    "        'recall': recall_score(test_targets, y_pred_final, zero_division=0),\n",
    "        'best_threshold': best_threshold\n",
    "    }\n",
    "    \n",
    "    print(f\"Advanced Model Results:\")\n",
    "    print(f\"AUC: {test_results['auc']:.4f}\")\n",
    "    print(f\"PR-AUC: {test_results['pr_auc']:.4f}\")\n",
    "    print(f\"F1: {test_results['f1']:.4f}\")\n",
    "    print(f\"Precision: {test_results['precision']:.4f}\")\n",
    "    print(f\"Recall: {test_results['recall']:.4f}\")\n",
    "    print(f\"Best Threshold: {test_results['best_threshold']:.4f}\")\n",
    "    \n",
    "    if len(np.unique(test_targets)) > 1:\n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(classification_report(test_targets, y_pred_final, \n",
    "                                  target_names=['Benign', 'Attack'], zero_division=0))\n",
    "    \n",
    "    # ==============================\n",
    "    # 7. Model Analysis - FIXED\n",
    "    # ==============================\n",
    "    print(\"\\n=== Model Analysis ===\")\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    if len(feature_names) == X_test_seq.shape[2]:  # Make sure dimensions match\n",
    "        importance_df = analyze_feature_importance(final_model, X_test_seq, feature_names)\n",
    "        print(\"Top 10 Most Important Features:\")\n",
    "        print(importance_df.head(10))\n",
    "    \n",
    "    # Plot comprehensive results\n",
    "    plot_advanced_results(train_losses, val_aucs, val_f1s, test_results)\n",
    "    \n",
    "    # Compare with original simple model\n",
    "    print(f\"\\n=== Performance Comparison ===\")\n",
    "    print(f\"Original LSTM - AUC: 0.9915, F1: 0.8939\")\n",
    "    print(f\"Advanced LSTM - AUC: {test_results['auc']:.4f}, F1: {test_results['f1']:.4f}\")\n",
    "    \n",
    "    improvement_auc = test_results['auc'] - 0.9915\n",
    "    improvement_f1 = test_results['f1'] - 0.8939\n",
    "    print(f\"AUC Improvement: {improvement_auc:+.4f}\")\n",
    "    print(f\"F1 Improvement: {improvement_f1:+.4f}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535dc057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
